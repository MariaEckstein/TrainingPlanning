---
title: "AnalyzingTheOtherTasks"
author: "Maria Eckstein"
date: "June 26, 2015"
output: pdf_document
---

```{r Load packages, echo = F, results = F, warning = F, message = F}
data_source = "2016"
do_exclude_trials = T                   # Exclude trials based on perseverance, RTs, etc?
ggsave_figures = T                      # Save figures as pngs onto the computer?
preprocess_data = T
home_dir = "C:/Users/maria/MEGAsync/TrainingPlanningProject"
figure_dir = file.path(home_dir, "TwoStepTask/model/RLDM")
data_dir = file.path(home_dir, "allResults/XlabData2016")
# model_dir = file.path(home_dir, "TwoStepTask/model")

source(file.path(home_dir, "TwoStepTask/model/TP_functions.R"))
library("reshape"); library("R.matlab"); library("car"); library("zoo"); library("plyr"); library("lme4"); library("lmerTest"); library("ggplot2"); theme_set(theme_bw()); library("gridExtra")
```

# Tower of London

+ Read in data set as `ToL` and set `numeric` and `factor` columns
+ Add column with minimum number of possible moves
+ Add columns indicating the subject `group` (model-free training session: `m_free`; model-based training session: `m_based`)
+ Save resulting data as .csv

```{r Prepare data, echo = F, warning = F}
ToL = read.table("auswertung_alle.txt",
                 header = T,
                 sep = " ", na.strings = "",
                 colClasses = c("factor", "factor", "factor", "factor", "numeric", "factor", "factor", "numeric", "factor", "numeric", "factor", "numeric", "numeric", "numeric", "numeric"))

ToL[ToL$SubjID %in% as.character(seq(100,250)),]

ToL$run = substr(ToL$SubjID, 4, 4)
ToL$run = factor(ToL$run, labels = paste("Run", 1:4))
ToL$SubjID = substr(ToL$SubjID, 1, 3)

ToL$session = ToL$TaskVersion = NULL
  
ToL = add_performance_columns_ToL()
ToL = add_group_columns(data = ToL)
plot(ToL$MadeMoves)   # Double-checked large numbers of moves in the raw data - everything matches up fine! 
summary(ToL)
write.table(ToL, file = "ToL_data.csv", quote = F, sep = ",", row.names = F)
```
```{r Plot made moves - min & estim moves ~ SubjID, echo = F, warning = F, fig.height = 9, fig.width = 9}
# Difference between estimated and executed moves
gg_made_estim = ggplot(ToL, aes(SubjID, Made_minus_EstimMoves)) +
  geom_boxplot() +
  labs(x = "Subject ID", y = "Made moves - estimated moves") +
  facet_wrap(~ run)
gg_made_estim

gg_made_min = ggplot(ToL, aes(SubjID, Made_minus_MinMoves)) +
  geom_boxplot() +
  labs(x = "Subject ID", y = "Made moves - min moves") +
  facet_wrap(~ run)
gg_made_min
```
```{r Plot made moves ~ min moves, echo = F, eval = F}
## Also of interest?
# The more moves are necessary minimally, the more the deviation in the executed moves
gg_min_spread = ggplot(ToL, aes(MinMoves, MadeMoves, color = SubjID)) +
  geom_point(position = "jitter") +
  geom_abline(intercept = 0, slope = 1) +
  coord_cartesian(xlim = c(0, 20), ylim = c(0, 20))
gg_min_spread

# Usually, more moves are needed than previously estimated
gg_estim_spread = ggplot(ToL, aes(EstimMoves, MadeMoves, color = SubjID)) +
  geom_point(position = "jitter") +
  geom_abline(intercept = 0, slope = 1) +
  coord_cartesian(xlim = c(0, 25), ylim = c(0, 25))
```

# Food task

```{r Theoretical reward probabilities in food task, echo = F, warning = F, message = F}
prob_of_rewards = expand.grid(number_of_rewards = 0:8, rew_prob = seq(0.1, 0.3, 0.05), probability = NA, cum_probability = NA)
prob_of_rewards$rew_prob = factor(prob_of_rewards$rew_prob)

for (rew_prob in seq(0.1, 0.3, 0.05)) {
  cum_prob = 0
  for (numb_of_rew in 8:0) {
    prob = choose(8, numb_of_rew) * (rew_prob ^ numb_of_rew) * ((1 - rew_prob) ^ (8 - numb_of_rew))
    cum_prob = cum_prob + prob
    prob_of_rewards[prob_of_rewards$number_of_rewards == numb_of_rew &
                    prob_of_rewards$rew_prob == rew_prob, c("probability", "cum_probability")] = c(prob, cum_prob)
  }
}

ggplot(prob_of_rewards, aes(number_of_rewards, probability * 100, color = rew_prob, group = rew_prob)) +
  geom_point() +
  geom_line() +
  labs(x = "Number of rewards (trial)", y = "Probability (%)", color = "Rew. prob. / int.")

ggplot(prob_of_rewards, aes(number_of_rewards, cum_probability * 100, color = rew_prob, group = rew_prob)) +
  geom_point() +
  geom_line() +
  labs(x = "Number of rewards (trial)", y = "Cumulative probability (%)", color = "Rew. prob. / int.")

```
```{r Read in food data and summarize by trials, echo = F, warning = F, message = F}

if (preprocess_data) {
  col_names = c("SubjID", "run", "trial", "rew_avail", "rew_rec", "n_cor", "n_fal")
  food_dat = data.frame()
  filenames = list.files(data_dir, pattern = "FOOD_performance_.*.mat")
  
  for (filename in filenames) {
    
    ### Read in measures (columns= trials; rows= time points within trials)
    data = readMat(file.path(data_dir, filename))$data
    reward_schedule = as.data.frame(data[[1]])
    reward_received = as.data.frame(data[[2]])
    cor_key = as.data.frame(data[[3]])
    fal_key = as.data.frame(data[[4]])
    key_time = as.data.frame(data[[5]])
    
    ### Calculate trial means (sum over time points within trials)
    SubjID = substr(filename, 18, 20)
    run = substr(filename, 23, 23)
    if (run == "A") {run = "Run 1"
    } else if (run == "B") {run = "Run 2"
    } else if (run == "C") {run = "Run 3"
    } else if (run == "D") {run = "Run 4"
    }
    
    subj_dat = cbind(SubjID, run, 1:60, matrix(colSums(reward_schedule)), matrix(colSums(reward_received)), matrix(colSums(cor_key)), matrix(colSums(fal_key)))
    colnames(subj_dat) = col_names
    
    ### Add to food_dat
    food_dat = rbind(food_dat, subj_dat)
  }
  
  food_dat = add_group_columns(food_dat)
  write.csv(food_dat, file.path(data_dir, "food_dat.csv"), row.names = F)
}

food_dat = read.csv(file.path(data_dir, "food_dat.csv"))

### Remove break trials
trialwise_food_dat = ddply(food_dat, .(trial), summarize, n_cor = mean(n_cor, na.rm = T))
summary(trialwise_food_dat)
break_trials = subset(trialwise_food_dat, n_cor == 0)$trial
food_dat = subset(food_dat, !trial %in% break_trials)
    
summary(food_dat)
head(food_dat)
```
```{r Food performance over time, echo = F, message = F, warning = F}

gg_food_over_trials = ggplot(food_dat, aes(trial, n_cor, color = training, group = training)) +
  stat_summary(fun.data = mean_cl_normal, fun.args = list(mult = 1), geom = "pointrange") +
  labs(y = "# correct button presses") +
  facet_wrap(~ run)
gg_food_over_trials

gg_food_over_trials2 = ggplot(food_dat, aes(trial, rew_rec - rew_avail, color = training, group = training)) +
  stat_summary(fun.data = mean_cl_normal, fun.args = list(mult = 1), geom = "pointrange") +
  labs(y = "Received reward - available rewards") +
  facet_wrap(~ run)
gg_food_over_trials2

sum_food_dat = ddply(food_dat, .(SubjID, run, training, training_s1), summarize,
                     rew_rec = mean(rew_rec, na.rm = T),
                     n_cor = mean(n_cor, na.rm = T))
summary(sum_food_dat)

gg_food_over_trials3 = ggplot(sum_food_dat, aes(run, n_cor, group = 1)) +
  stat_summary(fun.y = mean, color = "red", geom = "point") +
  geom_point(alpha = .2, position = "jitter") +
  facet_wrap(~ training)
gg_food_over_trials3
```
```{r Food performance by subject, echo = F, message = F, warning = F}

gg_food_by_subj = ggplot(food_dat, aes(SubjID, n_cor, group = SubjID, color = training)) +
  geom_boxplot() +
  labs(y = "# correct button presses / trial") +
  facet_wrap(~ run)
gg_food_by_subj

# ddply(sum_food_dat, .(run, training), summarize,
#       rew_rec = mean(rew_rec, na.rm = T),
#       sd_rew_rec = sd(rew_rec, na.rm = T),
#       n_cor = mean(n_cor, na.rm = T),
#       sd_n_cor = sd(n_cor, na.rm = T))
```

# Category tasks

```{r Read in category data, echo = F, message = F, warning = F}

if (preprocess_data) {
  col_names = c("SubjID", "run", "task", "trial", "ACC", "RT")
  cat_dat = data.frame()
  filenames = list.files(data_dir, pattern = "CAT0.*.mat")
  
  for (filename in filenames) {
    
    ### Get SubjID and run
    SubjID = substr(filename, 8, 10)
    run = substr(filename, 14, 14)
    task = substr(filename, 5, 6)
    if (run == "A") {run = "Run 1"
    } else if (run == "B") {run = "Run 2"
    } else if (run == "C") {run = "Run 3"
    } else if (run == "D") {run = "Run 4"
    }
    
    ### Read in measures (ACC & RT)
    exp = readMat(file.path(data_dir, filename))$exp
    index = dim(exp)[1] - 20
    
    if (dim(exp)[1] == 42 | (SubjID == "187" & run == "Run 4") | (SubjID == "149" & run == "Run 1")) {   # Participants with funny data sets...
      index = 21
    }
    if ((SubjID == "192" & run == "Run 4") | (SubjID == "193" & run == "Run 4")) {   # More funny data sets
    index = 23
    }
    
  
    ACC = matrix(exp[[index]][[1]])
    RT = matrix(exp[[index]][[2]])
    length(RT) = length(ACC)
    # key = matrix(exp[[index]][[4]])
    # theta = matrix(exp[[index]][[6]])
      
    ### Add to cat_dat
    subj_dat = cbind(SubjID, run, task, 1:length(ACC), ACC, RT)
    colnames(subj_dat) = col_names
    cat_dat = rbind(cat_dat, subj_dat)
  }
  cat_dat = subset(cat_dat, trial <= 110)   # only the first few participants got 120 trials
  cat_dat = add_group_columns(cat_dat)
  write.csv(cat_dat, file.path(data_dir, "cat_dat.csv"), row.names = F)
}
cat_dat = read.csv(file.path(data_dir, "cat_dat.csv"))

### Remove super-fast trials
cat_dat = subset(cat_dat, RT > 150 & !is.na(ACC))
cat_dat = subset(cat_dat, !trial %in% break_trials)
    
summary(cat_dat)
head(cat_dat)
```
```{r Cateogry performance over time, echo = F, message = F, warning = F}

gg_cat_over_trials = ggplot(cat_dat, aes(trial, ACC, color = training, group = training)) +
  stat_summary(fun.data = mean_cl_normal, fun.args = list(mult = 1), geom = "pointrange", alpha = .5) +
  labs(y = "ACC") +
  facet_grid(task ~ run)
gg_cat_over_trials

gg_cat_over_trials = ggplot(cat_dat, aes(trial, RT, color = training, group = training)) +
  stat_summary(fun.data = mean_cl_boot, geom = "pointrange", alpha = .5) +
  labs(y = "RT") +
  facet_grid(task ~ run)
gg_cat_over_trials

sum_cat_dat = ddply(cat_dat, .(SubjID, run, task, training, training_s1), summarize,
                     ACC = mean(ACC, na.rm = T),
                     RT = median(RT, na.rm = T))
summary(sum_cat_dat)

gg_cat_over_trials3 = ggplot(sum_cat_dat, aes(run, ACC, group = 1, color = task)) +
  stat_summary(fun.y = mean, geom = "point", color = "black") +
  geom_point(alpha = .5, position = "jitter") +
  facet_wrap(~ training)
gg_cat_over_trials3

```
```{r Category performance by subject, echo = F, message = F, warning = F}

gg_cat_by_subj = ggplot(cat_dat, aes(SubjID, ACC, group = SubjID, color = training)) +
  stat_summary(fun.data = mean_cl_normal, geom = "pointrange") +
  labs(y = "ACC") +
  facet_grid(task ~ run)
gg_cat_by_subj

```


### 2-step Task:

+ Read in raw data set as `ts` and parameter data set as `ts_params`; set columns to `numeric` and `factor`
+ Add columns indicating the subject `group` (model-free training session: `m_free`; model-based training session: `m_based`)
+ Exclude trials with key perseverations (the same key pressed at least 10 times in a row) 

```{r, echo = F, warning = F}
# ts = read_in_2step()
# ts = add_group_columns(data = ts)
# ts_clean = remove_perseverance_trials(data = ts)[[1]]
# # write.table(ts, file = "2steptask/Results/all/ts_clean.csv", quote = F, sep = ",", row.names = F)
# # summary(ts_clean)
# 
# ts_params = read_in_2step_parameters()
# ts_params = add_group_columns(ts_params)
# # summary(ts_params)
```


## Is training performance an additional predictor of how subjects solve the 2-step Task?

### What indicators of performance should we use?

+ Overall hit rate, false alarm rate, d-prime? ("*How well did the subjects perform in the training?*")
+ Reaction time? ("*Did they perceive the tasks as easy and solve the fluently?*")
+ Increases in performance over time? ("*How much did they learn through the training? How big was the effect of the training?*")

#### 2-step Task:

+ Money earned?
+ Number of optimal decisions? (Problem: How to determine that? Based on theoretical probabilities or reward history?)

#### Tower of London:

1.  ***How big was the difference between the number of estimated and executed moves?***  
    This indicates how good a subject was at making a precise plan and sticking to it.
    
2.  ***How many extra moves did the subjects need to solve the problems (above the minimum possible number)?***  
    This indicates how good a subject was at finding the best possible solution.
    
Both measures are plausible as measures of ToL performance and vary between subjects:


3.  ***How much did performance increase through the training?***  
    This indicates how much effect the training had at all on the subjects. Here is the difference in the performance measures above between the first and second run of the Tower of London.
    
```{r, echo = F, warning = F, fig.height = 4.5, fig.width = 9}
# M_based = create_summary_data_frames()[[1]]
# M_free  = create_summary_data_frames()[[2]]
# 
# plot_ToL_diffscores()
```


##### 2-step Task:

1. ***How many coins did the subjects collect overall?***

```{r, echo = F, warning = F, fig.height = 9, fig.width = 9}
# source("TP_functions.R")
# tsTotalACCPlot = plot_ts_perf_total(variable = "reward")
# tsTotalACCPlot
```

2. ***How fast were they at responding?***  
   Response times differ between subjects and seem to be consistent from the 1st to the 2nd run.  
   They might therefore be a good indicator of performance.

```{r, echo = F, warning = F, fig.height = 9, fig.width = 9}
# tsTotalRTPlot = plot_ts_perf_total(variable = "RT")
# tsTotalRTPlot
```

3. ***How much did their performance change over the course of the training?***  
   That is, ... .
   
```{r, echo = F, warning = F, fig.height = 9, fig.width = 9}

# GNACCOverTimePlot = plot_labassgn_perf_over_time(data = GN, variable = "ACC", task_name = "GoNogo", section_size = 10)[[1]]
# GNRTOverTimePlot = plot_labassgn_perf_over_time(data = GN, variable = "RT", task_name = "GoNogo", section_size = 10)[[1]]
# 
# grid.arrange(GNACCOverTimePlot, GNRTOverTimePlot, nrow = 2)

```

+ *Rewards and response times _are_ independent*. As expected, there is *no* difference in response time between rewarded and non-rewarded trials:

```{r, echo = F}
# r0 = with(ts, RT1[reward == "No reward"] + RT2[reward == "No reward"])
# r1 = with(ts, RT1[reward == "Reward"] + RT2[reward == "Reward"])
# t.test(r0, r1)
```

##### Is performance in the tasks related to performance in ToL/GoNogo?



#### Does good training performance predict good 2-step performance?

+ __Median split__ based on Association, GoNogo, Tower of London, and Labyrinth tasks; does 2-step performance differ?
+ __Pearson correlation__ between training task performance and 2-step performance?
+ __Hypothesis__: It might...

#### Does good training performance predict stronger training effects?

+ __Regression__ with the predictors _training_, _session_, and _performace_ on the outcome 2-step _strategy_
+ __Hypothesis__:
    + _Main effect of training_: YES! (see above)
    + _Main effect of performance_: Maybe! The better the performance, the more model-based do they approach the task (Good performance in either training condition might predict model-based strategy? Because that is simply the right way to do the task and subjects are obviously able to do tasks the right way...
    + _Interaction between training and performance_: YES! Good performance in the planning condition leads to a more model-based strategy; good performance in the association condition leads to a more model-free strategy.
    + _Interactions with session_: Maybe! (see above)
    
### Is meta-cognition and additional predictor of how subjects solve the 2-step task?

* __Regression__ with the predictors _training_ (planning vs. association), _session_, and _metacognition_ on the outcome 2-step _strategy_
    + __Hypothesis__: The more meta-cognitive introspection, the better the training works because they get the similarities between the tasks and apply it in the new one.

#### What should we use as a measure of meta-cognition?

* Did the subjects mention something in the lines of "model-based"/"model-free" or "goal-directed"/"habitual" or "planning", "strategy"?
